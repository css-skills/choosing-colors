---
title: "Optimizing selection of color palettes"
author: "Computation Skills Workshop"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  cache = TRUE,
  message = FALSE,
  warning = FALSE,
  echo = FALSE,
  fig.retina = 2, fig.width = 12
)

library(tidyverse)
library(readxl)
library(urbnmapr)
library(here)
library(patchwork)
library(knitr)
library(palmerpenguins)
library(colorblindr)
library(rnaturalearth)

theme_set(theme_minimal())

set.seed(123)
theme_set(theme_minimal(base_size = rcfss::base_size))
```

# What to color by

```{r}
# get unemployment data and wrangle
unemp <- read_excel(path = here("data", "bls-unemployment.xlsx"), skip = 3) %>%
  # extract state_fips code
  mutate(state_fips = str_sub(string = `Series ID`, start = 6L, end = 7L)) %>%
  # tidy into long form
  select(state_fips, everything(), -`Series ID`) %>%
  pivot_longer(cols = -state_fips, names_to = "month_year", values_to = "unemp") %>%
  separate(col = month_year, into = c("month", "year"), convert = TRUE) %>%
  # aggregate to annual
  group_by(state_fips, year) %>%
  summarize(unemp = mean(unemp, na.rm = TRUE) / 100)

# get US shapefile
states_sf <- get_urbn_map("states", sf = TRUE)

# combine
unemp_sf <- left_join(states_sf, unemp)
```

```{r}
# create choropleth for 2010
choropleth <- unemp_sf %>%
  filter(year == 2010) %>%
  ggplot(mapping = aes(fill = unemp)) +
  geom_sf(color = "white") +
  scale_fill_viridis_c(labels = scales::percent, option = "magma") +
  labs(fill = "2010")

# create line chart highlighting Texas and New York
line_chart <- ggplot(data = unemp, mapping = aes(x = year, y = unemp, group = state_fips)) +
  geom_line(alpha = 0.1) +
  geom_line(
    data = unemp %>%
      filter(state_fips %in% c(48, 36)) %>%
      mutate(state_fips = factor(state_fips, levels = c(36, 48), labels = c("New York", "Texas"))),
    mapping = aes(color = state_fips),
    size = 1
  ) +
  scale_y_continuous(labels = scales::percent) +
  scale_color_brewer(type = "qual") +
  labs(
    x = "Year",
    y = "Unemployment rate",
    color = NULL
  ) +
  theme(
    strip.text.x = element_blank(),
    strip.background = element_rect(color = "white", fill = "white"),
    legend.position = c(.9, .9)
  )

choropleth + line_chart
```

---

# Categorical color scales

```{r}
include_graphics(path = here("images", "hue-example.png"))
include_graphics(path = here("images", "hue-example2.png"))
```

.footnote[Sources: FiveThirtyEight, The Economist]

---

# Sequential color scales

```{r}
include_graphics(path = here("images", "seq-class-ex.png"))
include_graphics(path = here("images", "seq-unclass-ex.png"))
```

.footnote[Sources: New York Times, Datawrapper]

---

# Diverging color scales

```{r}
include_graphics(path = here("images", "div-class-ex.png"))
include_graphics(path = here("images", "div-unclass-ex.png"))
```

.footnote[Sources: Axios, Opportunity Atlas]

---

# Highlighting/de-emphasizing

```{r}
include_graphics(path = here("images", "highlight-zero.png"))
include_graphics(path = here("images", "deemphasize-cat.png"))
include_graphics(path = here("images", "bin-grad-na.png"))
```

.footnote[Sources: The Guardian, The Pudding, Bloomberg]

---

# Choosing a color scale

- Emphasis on interpretability and accessibility
- Default palettes are less than desirable
- Variables may require transformations

---

# Default palette in `ggplot2`

```{r}
# generate simulated data points
plots <- purrr::map(1:9, ~ gg_color_swatches(n = .x) +
  ggtitle(paste(.x, "color")))

wrap_plots(plots)
```

---

# Common forms of color vision deficiency

### Red-green

- Deuteranomaly
- Protanomaly
- Protanopia and deuteranopia

### Blue-yellow

- Tritanomaly
- Tritanopia

### Complete color vision deficiency

- Monochromacy

---

# Inspecting for color vision deficiency

```{r}
# create basic penguins plot
pen_fig <- ggplot(data = penguins, mapping = aes(x = body_mass_g, fill = species)) +
  geom_density(alpha = 0.6) +
  labs(
    x = "Body mass (in grams)",
    fill = "Species"
  ) +
  theme(legend.position = "bottom")
pen_fig
```

---

# Inspecting for color vision deficiency

```{r echo = TRUE, eval = FALSE}
library(colorblindr)
cvd_grid(plot = pen_fig)
```

```{r}
{
  pen_fig +
    theme_minimal(base_size = 11)
} %>%
  cvd_grid()
```

---

# Inspecting for color deficiency

```{r}
gg_color_swatches(n = 8) +
  {
    gg_color_swatches(n = 8) %>%
      cvd_grid()
  } +
  plot_layout(widths = c(30, 70)) +
  plot_annotation(title = "Default color palette for 8")
```

---

# Inspecting for color deficiency

```{r}
gg_color_gradient(n = 200) +
  {
    gg_color_gradient(n = 200) %>%
      cvd_grid()
  } +
  plot_layout(widths = c(30, 70)) +
  plot_annotation(title = "Default continuous gradient")
```

---

# Inspecting for color deficiency

```{r}
{
  choropleth +
    theme_void() +
    theme(legend.position = "none")
} +
  {
    {
      choropleth +
        theme_void() +
        theme(legend.position = "none")
    } %>%
      cvd_grid()
  } +
  plot_layout(widths = c(30, 70))
```

---

class: center, middle, invert

# When to use quantitative or qualitative color scales?

---

```{r}
include_graphics(path = here("images", "quant-qual.png"))
```

---

# Use hues for nominal variables

```{r}
include_graphics(path = here("images", "unordered.png"))
```

---

# Use hues for nominal variables

```{r}
include_graphics(path = here("images", "unemp-best.png"))
```

---

# Quantitative $\neq$ continuous

```{r}
include_graphics(path = here("images", "likert.png"))
```

---

# Shades to emphasize order

```{r}
include_graphics(path = here("images", "treemap.png"))
```


---

# Overcomplicating graphs

```{r}
include_graphics(path = here("images", "treemap-third-var.png"))
```

---

# Overcomplicating graphs

```{r}
# import Few dataset
few_df <- read_csv(file = here("data", "data-AYui0.csv")) %>%
  rename(state = X.1) %>%
  pivot_longer(cols = -state, names_to = "quarter", values_to = "var_to_plan") %>%
  mutate(state = factor(state, levels = c("California", "New Jersey", "Louisiana", "Montana")),,
         var_to_plan = var_to_plan / 100)

# recreate the plot
ggplot(data = few_df, mapping = aes(x = quarter, y = var_to_plan, fill = state)) +
  geom_col(position = "dodge") +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_brewer(direction = -1) +
  labs(
    title = "Manufacturing production: Variance to plan",
    x = NULL,
    y = NULL,
    fill = NULL
  ) +
  theme(legend.position = "bottom")
```

---

# Correcting the graph

```{r}
ggplot(data = few_df, mapping = aes(x = quarter, y = var_to_plan, group = state, color = state)) +
  geom_line() +
  ggrepel::geom_text_repel(data = few_df %>% filter(quarter == "Q4"),
                           mapping = aes(label = state), direction = "y", nudge_x = .3, size = 6) +
  scale_y_continuous(labels = scales::percent) +
  scale_color_brewer(palette = "Set1") +
  labs(
    title = "Manufacturing production: Variance to plan",
    x = NULL,
    y = NULL,
    fill = NULL
  ) +
  theme(legend.position = "none")
```

---

# Encoding a new variable

```{r}
include_graphics(path = here("images", "google-algorithm.png"))
```

.footnote[Graphic detail page "Google's algorithm" in The Economist from June 8th, 2019]

---

# Double-encoded line chart

```{r}
include_graphics(path = here("images", "double-encode-lines.png"))
```

---

# Shades to distinguish subcategories

```{r}
include_graphics(path = here("images", "subcategories.png"))
```

---

# Shades to distinguish highlighted areas

```{r}
include_graphics(path = here("images", "double-encode-lines.png"))
```

---

# Stick to shades of one hue

```{r}
include_graphics(path = here("images", "hues-single.png"))
```

---

# Except when you shouldn't!

- Meaningful middle point
- Emphasize extremes
- See more differences

---

# Meaningful middle point

```{r}
include_graphics(path = here("images", "div-palette.png"))
```

- Zero
- 50%
- Average
- Agreed threshold
- A target

---

# WTF?

```{r}
include_graphics(path = here("images", "pepmusic.png"))
```

---

# Emphasize highest values

```{r}
# get internet usage data file
internet_use <- read_csv(file = here("data", "internet-consumption.csv")) %>%
  rename(usage = `internet usage`) %>%
  mutate(usage = usage / 100)

# get global shapefile
world <- ne_countries(scale = "medium", returnclass = "sf")

# join together
internet_sf <- left_join(x = world, y = internet_use, by = c("iso_a3" = "code"))
```

```{r}
internet_plot <- ggplot(data = internet_sf, mapping = aes(fill = usage)) +
  geom_sf(color = "white") +
  coord_sf(crs = "+proj=robin") +
  labs(title = "Share of individuals using the internet in the last 3 months",
       subtitle = "2015",
       fill = NULL) +
  theme_void(base_size = 14)

internet_plot +
  scale_fill_distiller(type = "seq", labels = scales::percent)
```

---

# Emphasize extremes

```{r}
internet_plot +
  scale_fill_distiller(type = "div", labels = scales::percent)
```

---

# Increased range in scale

```{r}
include_graphics(path = here("images", "births-div.png"))
```

---

# Increased range in scale

```{r}
include_graphics(path = here("images", "births-seq.png"))
```



